{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação de uma Rede Neural com Tensorflow\n",
    "\n",
    "No exemplo a seguir, veremos em ação a uma Rede Neural Convolucional (CNN) em um problema de classificação de imagens. Queremos mostrar o processo de construção de uma rede CNN: quais são as etapas para executar e que raciocínio precisa ser feito para executar um dimensionamento adequado de toda a rede e, claro, como implementá-lo com o TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carreguando e preparamdp os dados do MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramonfsilva/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defina todos os parâmetros da CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 128\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrada de dados MNIST (cada forma é de 28x28 pixels de matriz):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O total de 10 classes do MNIST (0-9 dígitos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para reduzir o encaixe, aplicamos a técnica de dropout. Este termo refere-se ao abandono de unidades (oculto, entrada e saída) em uma rede neural. Decidir quais neurônios eliminar é aleatório; Uma maneira é aplicar uma probabilidade, como veremos em nosso código. Por esse motivo, definimos o seguinte parâmetro (a ser ajustado):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.75 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defina os espaços reservados para o gráfico de entrada. O espaço reservado x contém a entrada de dados MNIST (exatamente 728 pixels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, n_input])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, mudamos a forma das imagens de entrada 4D para um tensor, usando o operador de reformulação TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = tf.reshape(x, shape=[-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A segunda e terceira dimensões correspondem à largura e altura da imagem, enquanto a última dimensão é o número total de canais de cor (no nosso caso 1).\n",
    "\n",
    "Assim, podemos exibir nossa imagem de entrada como um tensor bidimensional, de tamanho 28x28:\n",
    "    \n",
    "![title](img/digit.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeira camada convolucional\n",
    "Cada neurônio da camada oculta é conectado a um pequeno subconjunto do tensor de entrada de dimensão 5x5. Isso implica que a camada oculta terá um tamanho 24x24. Também definimos e inicializamos os tensores de pesos compartilhados e viés compartilhado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc1 = tf.Variable(tf.random_normal([5, 5, 1, 32])) \n",
    "bc1 = tf.Variable(tf.random_normal([32]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembre-se de que, para reconhecer uma imagem, precisamos de mais do que um mapa de recursos. O número é apenas o número de mapas de recursos que estamos considerando para essa primeira camada. No nosso caso, a camada convolucional é composta por 32 mapas de características.\n",
    "\n",
    "O próximo passo é a construção da primeira camada de convolução, conv1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(img, w, b):\n",
    "  return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(img, w,strides=[1, 1, 1, 1],padding='SAME'),b))\n",
    "\n",
    "conv1 = conv2d(_X,wc1,bc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma maneira de representar a camada convolucional, ou seja, conv1, é a seguinte:\n",
    "\n",
    "\n",
    "![title](img/first_hidden_layer.jpg)\n",
    "\n",
    "Após a operação de convolução, impomos a etapa de agrupamento que simplifica as informações de saída da camada convolucional criada anteriormente.\n",
    "\n",
    "Em nosso exemplo, vamos considerar uma região 2x2 da camada de convolução e resumiremos as informações em cada ponto da camada de pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(img, k):\n",
    "    return tf.nn.max_pool(img, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "conv1 = max_pool(conv1, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A figura a seguir mostra as camadas CNNs após a operação de agrupamento e convolução:\n",
    "\n",
    "![title](img/max_pooling.jpg)\n",
    "\n",
    "A última operação é reduzir o overfitting aplicando os operadores tf.nn.dropout TensorFlow na camada convolucional. Para fazer isso, criamos um marcador de posição para a probabilidade (keep_prob) de que a saída de um neurônio é mantida durante o abandono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf. placeholder(tf.float32)\n",
    "conv1 = tf.nn.dropout(conv1,keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segunda camada convolucional\n",
    "Para a segunda camada oculta, devemos aplicar as mesmas operações que a primeira camada, e assim definimos e inicializamos os tensores de pesos compartilhados e viés compartilhado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc2 = tf.Variable(tf.random_normal([5, 5, 32, 64]))\n",
    "bc2 = tf.Variable(tf.random_normal([64]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como você pode notar, esta segunda camada oculta terá 64 recursos para uma janela 5x5, enquanto o número de camadas de entrada será dado a partir da primeira camada obtida pela convolução. Em seguida, aplicamos uma segunda camada ao tensor convolucional conv1, mas desta vez aplicamos 64 conjuntos de filtros 5x5 cada para as 32 camadas conv1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = conv2d(conv1,wc2,bc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso nos dá 64 arrays 14x14 que reduzimos com o pool máximo para 64 arrays 7x7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = max_pool(conv2, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, novamente usamos a operação de dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = tf.nn.dropout(conv2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
